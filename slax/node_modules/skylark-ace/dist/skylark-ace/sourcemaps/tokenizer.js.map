{"version":3,"sources":["tokenizer.js"],"names":["define","require","exports","module","config","MAX_TOKEN_COUNT","Tokenizer","rules","key","this","states","regExps","matchMappings","state","ruleRegExps","matchTotal","mapping","defaultToken","flag","splitterRurles","i","length","rule","caseInsensitive","regex","RegExp","toString","slice","adjustedregex","matchcount","exec","Array","isArray","token","reportError","groupCount","tokenArray","onMatch","$arrayTokens","$applyToken","test","replace","match","digit","parseInt","removeCapturingGroups","splitRegex","push","forEach","createSplitterRegexp","join","$setMaxTokenCount","m","str","values","types","apply","type","value","tokens","l","src","x","y","indexOf","stack","inChClass","lastCapture","esc","parenOpen","parenClose","square","index","end","start","substr","substring","charAt","getLineTokens","line","startState","shift","currentState","re","lastIndex","matchAttempts","skipped","undefined","next","consumeLineEnd","merge","unshift","call","prototype"],"mappings":";;;;;;;AA8BAA,OAAO,SAASC,QAASC,QAASC,QAClC,aAEA,IAAIC,EAASH,QAAQ,YAEjBI,EAAkB,IAYlBC,EAAY,SAASC,GAKrB,IAAK,IAAIC,KAJTC,KAAKC,OAASH,EAEdE,KAAKE,WACLF,KAAKG,iBACWH,KAAKC,OAAQ,CAQzB,IAPA,IAAIG,EAAQJ,KAAKC,OAAOF,GACpBM,KACAC,EAAa,EACbC,EAAUP,KAAKG,cAAcJ,IAAQS,aAAc,QACnDC,EAAO,IAEPC,KACKC,EAAI,EAAGA,EAAIP,EAAMQ,OAAQD,IAAK,CACnC,IAAIE,EAAOT,EAAMO,GAKjB,GAJIE,EAAKL,eACLD,EAAQC,aAAeK,EAAKL,cAC5BK,EAAKC,kBACLL,EAAO,MACO,MAAdI,EAAKE,MAAT,CAGIF,EAAKE,iBAAiBC,SACtBH,EAAKE,MAAQF,EAAKE,MAAME,WAAWC,MAAM,GAAI,IAIjD,IAAIC,EAAgBN,EAAKE,MACrBK,EAAa,IAAIJ,OAAO,OAASG,EAAgB,UAAUE,KAAK,KAAKT,OAAS,EAC9EU,MAAMC,QAAQV,EAAKW,OACM,GAArBX,EAAKW,MAAMZ,QAA6B,GAAdQ,EAC1BP,EAAKW,MAAQX,EAAKW,MAAM,GACjBJ,EAAa,GAAKP,EAAKW,MAAMZ,QACpCZ,KAAKyB,YAAY,qDACbZ,KAAMA,EACNa,WAAYN,EAAa,IAE7BP,EAAKW,MAAQX,EAAKW,MAAM,KAExBX,EAAKc,WAAad,EAAKW,MACvBX,EAAKW,MAAQ,KACbX,EAAKe,QAAU5B,KAAK6B,cAEI,mBAAdhB,EAAKW,OAAwBX,EAAKe,UAE5Cf,EAAKe,QADLR,EAAa,EACEpB,KAAK8B,YAELjB,EAAKW,OAGxBJ,EAAa,IACT,OAAOW,KAAKlB,EAAKE,OAEjBI,EAAgBN,EAAKE,MAAMiB,QAAQ,cAAe,SAASC,EAAOC,GAC9D,MAAO,MAAQC,SAASD,EAAO,IAAM5B,EAAa,MAGtDc,EAAa,EACbD,EAAgBnB,KAAKoC,sBAAsBvB,EAAKE,QAE/CF,EAAKwB,YAAmC,iBAAdxB,EAAKW,OAChCd,EAAe4B,KAAKzB,IAG5BN,EAAQD,GAAcK,EACtBL,GAAcc,EAEdf,EAAYiC,KAAKnB,GAGZN,EAAKe,UACNf,EAAKe,QAAU,OAGlBvB,EAAYO,SACbL,EAAQ,GAAK,EACbF,EAAYiC,KAAK,MAGrB5B,EAAe6B,QAAQ,SAAS1B,GAC5BA,EAAKwB,WAAarC,KAAKwC,qBAAqB3B,EAAKE,MAAON,IACzDT,MAEHA,KAAKE,QAAQH,GAAO,IAAIiB,OAAO,IAAMX,EAAYoC,KAAK,OAAS,QAAShC,MAIhF,WACIT,KAAK0C,kBAAoB,SAASC,GAC9B/C,EAAsB,EAAJ+C,GAGtB3C,KAAK8B,YAAc,SAASc,GACxB,IAAIC,EAAS7C,KAAKqC,WAAWhB,KAAKuB,GAAK1B,MAAM,GACzC4B,EAAQ9C,KAAKwB,MAAMuB,MAAM/C,KAAM6C,GAGnC,GAAqB,iBAAVC,EACP,QAASE,KAAMF,EAAOG,MAAOL,IAGjC,IADA,IAAIM,KACKvC,EAAI,EAAGwC,EAAIL,EAAMlC,OAAQD,EAAIwC,EAAGxC,IACjCkC,EAAOlC,KACPuC,EAAOA,EAAOtC,SACVoC,KAAMF,EAAMnC,GACZsC,MAAOJ,EAAOlC,KAG1B,OAAOuC,GAGXlD,KAAK6B,aAAe,SAASe,GACzB,IAAKA,EACD,SACJ,IAAIC,EAAS7C,KAAKqC,WAAWhB,KAAKuB,GAClC,IAAKC,EACD,MAAO,OAGX,IAFA,IAAIK,KACAJ,EAAQ9C,KAAK2B,WACRhB,EAAI,EAAGwC,EAAIL,EAAMlC,OAAQD,EAAIwC,EAAGxC,IACjCkC,EAAOlC,EAAI,KACXuC,EAAOA,EAAOtC,SACVoC,KAAMF,EAAMnC,GACZsC,MAAOJ,EAAOlC,EAAI,KAG9B,OAAOuC,GAGXlD,KAAKoC,sBAAwB,SAASgB,GAKlC,OAJQA,EAAIpB,QACR,yCACA,SAASqB,EAAGC,GAAI,OAAOA,EAAI,MAAQD,KAK3CrD,KAAKwC,qBAAuB,SAASY,EAAK3C,GACtC,IAA2B,GAAvB2C,EAAIG,QAAQ,OAAc,CAC1B,IAAIC,EAAQ,EACRC,GAAY,EACZC,KACJN,EAAIpB,QAAQ,uCAAwC,SAChDW,EAAGgB,EAAKC,EAAWC,EAAYC,EAAQC,GAmBvC,OAjBIN,EACAA,EAAsB,KAAVK,EACLA,EACPL,GAAY,EACLI,GACHL,GAASE,EAAYF,QACrBE,EAAYM,IAAMD,EAAM,EACxBL,EAAYF,OAAS,GAEzBA,KACOI,IACPJ,IACwB,GAApBI,EAAUhD,SACV8C,EAAYF,MAAQA,EACpBE,EAAYO,MAAQF,IAGrBpB,IAGY,MAAnBe,EAAYM,KAAe,QAAQjC,KAAKqB,EAAIc,OAAOR,EAAYM,QAC/DZ,EAAMA,EAAIe,UAAU,EAAGT,EAAYO,OAASb,EAAIc,OAAOR,EAAYM,MAO3E,MAHqB,KAAjBZ,EAAIgB,OAAO,KAAWhB,EAAM,IAAMA,GACJ,KAA9BA,EAAIgB,OAAOhB,EAAIxC,OAAS,KAAWwC,GAAO,KAEvC,IAAIpC,OAAOoC,GAAM3C,GAAM,IAAIuB,QAAQ,IAAK,MAOnDhC,KAAKqE,cAAgB,SAASC,EAAMC,GAChC,GAAIA,GAAmC,iBAAdA,EAGF,UADnBA,GADIf,EAAQe,EAAWrD,MAAM,IACV,MAEfsC,EAAMgB,QACND,EAAaf,EAAMgB,cAGvB,IAAIhB,KAER,IAAIiB,EAAeF,GAAc,QAC7BnE,EAAQJ,KAAKC,OAAOwE,GACnBrE,IACDqE,EAAe,QACfrE,EAAQJ,KAAKC,OAAOwE,IAExB,IAAIlE,EAAUP,KAAKG,cAAcsE,GAC7BC,EAAK1E,KAAKE,QAAQuE,GACtBC,EAAGC,UAAY,EAQf,IANA,IAAI1C,EAAOiB,KACPyB,EAAY,EACZC,EAAgB,EAEhBpD,GAASwB,KAAM,KAAMC,MAAO,IAEzBhB,EAAQyC,EAAGrD,KAAKiD,IAAO,CAC1B,IAAItB,EAAOzC,EAAQC,aACfK,EAAO,KACPoC,EAAQhB,EAAM,GACd8B,EAAQW,EAAGC,UAEf,GAAIZ,EAAQd,EAAMrC,OAAS+D,EAAW,CAClC,IAAIE,EAAUP,EAAKH,UAAUQ,EAAWZ,EAAQd,EAAMrC,QAClDY,EAAMwB,MAAQA,EACdxB,EAAMyB,OAAS4B,GAEXrD,EAAMwB,MACNE,EAAOZ,KAAKd,GAChBA,GAASwB,KAAMA,EAAMC,MAAO4B,IAIpC,IAAK,IAAIlE,EAAI,EAAGA,EAAIsB,EAAMrB,OAAO,EAAGD,IAChC,QAAqBmE,IAAjB7C,EAAMtB,EAAI,GAAd,CAMIqC,GAHJnC,EAAOT,EAAMG,EAAQI,KAEZiB,QACEf,EAAKe,QAAQqB,EAAOwB,EAAcjB,EAAOc,GAEzCzD,EAAKW,MAEZX,EAAKkE,OAEDN,EADoB,iBAAb5D,EAAKkE,KACGlE,EAAKkE,KAELlE,EAAKkE,KAAKN,EAAcjB,IAG3CpD,EAAQJ,KAAKC,OAAOwE,MAEhBzE,KAAKyB,YAAY,sBAAuBgD,GACxCA,EAAe,QACfrE,EAAQJ,KAAKC,OAAOwE,IAExBlE,EAAUP,KAAKG,cAAcsE,GAC7BE,EAAYZ,GACZW,EAAK1E,KAAKE,QAAQuE,IACfE,UAAYZ,GAEflD,EAAKmE,iBACLL,EAAYZ,GAChB,MAGJ,GAAId,EACA,GAAoB,iBAATD,EACDnC,IAAuB,IAAfA,EAAKoE,OAAoBzD,EAAMwB,OAASA,GAG9CxB,EAAMwB,MACNE,EAAOZ,KAAKd,GAChBA,GAASwB,KAAMA,EAAMC,MAAOA,IAJ5BzB,EAAMyB,OAASA,OAMhB,GAAID,EAAM,CACTxB,EAAMwB,MACNE,EAAOZ,KAAKd,GAChBA,GAASwB,KAAM,KAAMC,MAAO,IAC5B,IAAStC,EAAI,EAAGA,EAAIqC,EAAKpC,OAAQD,IAC7BuC,EAAOZ,KAAKU,EAAKrC,IAI7B,GAAIgE,GAAaL,EAAK1D,OAClB,MAIJ,GAFA+D,EAAYZ,EAERa,IAAkBhF,EAAiB,CAQnC,IAPIgF,EAAgB,EAAIN,EAAK1D,QACzBZ,KAAKyB,YAAY,uCACb8C,WAAYA,EACZD,KAAMA,IAIPK,EAAYL,EAAK1D,QAChBY,EAAMwB,MACNE,EAAOZ,KAAKd,GAChBA,GACIyB,MAAOqB,EAAKH,UAAUQ,EAAWA,GAAa,KAC9C3B,KAAM,YAGdyB,EAAe,QACfjB,KACA,OAWR,OAPIhC,EAAMwB,MACNE,EAAOZ,KAAKd,GAEZgC,EAAM5C,OAAS,GACX4C,EAAM,KAAOiB,GACbjB,EAAM0B,QAAQ,OAAQT,IAG1BvB,OAASA,EACT9C,MAAQoD,EAAM5C,OAAS4C,EAAQiB,IAIvCzE,KAAKyB,YAAc9B,EAAO8B,cAE3B0D,KAAKtF,EAAUuF,WAElB3F,QAAQI,UAAYA","file":"../tokenizer.js","sourcesContent":["/* ***** BEGIN LICENSE BLOCK *****\r\n * Distributed under the BSD license:\r\n *\r\n * Copyright (c) 2010, Ajax.org B.V.\r\n * All rights reserved.\r\n *\r\n * Redistribution and use in source and binary forms, with or without\r\n * modification, are permitted provided that the following conditions are met:\r\n *     * Redistributions of source code must retain the above copyright\r\n *       notice, this list of conditions and the following disclaimer.\r\n *     * Redistributions in binary form must reproduce the above copyright\r\n *       notice, this list of conditions and the following disclaimer in the\r\n *       documentation and/or other materials provided with the distribution.\r\n *     * Neither the name of Ajax.org B.V. nor the\r\n *       names of its contributors may be used to endorse or promote products\r\n *       derived from this software without specific prior written permission.\r\n *\r\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\r\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\r\n * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\r\n * DISCLAIMED. IN NO EVENT SHALL AJAX.ORG B.V. BE LIABLE FOR ANY\r\n * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\r\n * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\r\n * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\r\n * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\r\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\r\n *\r\n * ***** END LICENSE BLOCK ***** */\r\n\r\ndefine(function(require, exports, module) {\r\n\"use strict\";\r\n\r\nvar config = require(\"./config\");\r\n// tokenizing lines longer than this makes editor very slow\r\nvar MAX_TOKEN_COUNT = 2000;\r\n/**\r\n * This class takes a set of highlighting rules, and creates a tokenizer out of them. For more information, see [the wiki on extending highlighters](https://github.com/ajaxorg/ace/wiki/Creating-or-Extending-an-Edit-Mode#wiki-extendingTheHighlighter).\r\n * @class Tokenizer\r\n **/\r\n\r\n/**\r\n * Constructs a new tokenizer based on the given rules and flags.\r\n * @param {Object} rules The highlighting rules\r\n *\r\n * @constructor\r\n **/\r\nvar Tokenizer = function(rules) {\r\n    this.states = rules;\r\n\r\n    this.regExps = {};\r\n    this.matchMappings = {};\r\n    for (var key in this.states) {\r\n        var state = this.states[key];\r\n        var ruleRegExps = [];\r\n        var matchTotal = 0;\r\n        var mapping = this.matchMappings[key] = {defaultToken: \"text\"};\r\n        var flag = \"g\";\r\n\r\n        var splitterRurles = [];\r\n        for (var i = 0; i < state.length; i++) {\r\n            var rule = state[i];\r\n            if (rule.defaultToken)\r\n                mapping.defaultToken = rule.defaultToken;\r\n            if (rule.caseInsensitive)\r\n                flag = \"gi\";\r\n            if (rule.regex == null)\r\n                continue;\r\n\r\n            if (rule.regex instanceof RegExp)\r\n                rule.regex = rule.regex.toString().slice(1, -1);\r\n\r\n            // Count number of matching groups. 2 extra groups from the full match\r\n            // And the catch-all on the end (used to force a match);\r\n            var adjustedregex = rule.regex;\r\n            var matchcount = new RegExp(\"(?:(\" + adjustedregex + \")|(.))\").exec(\"a\").length - 2;\r\n            if (Array.isArray(rule.token)) {\r\n                if (rule.token.length == 1 || matchcount == 1) {\r\n                    rule.token = rule.token[0];\r\n                } else if (matchcount - 1 != rule.token.length) {\r\n                    this.reportError(\"number of classes and regexp groups doesn't match\", { \r\n                        rule: rule,\r\n                        groupCount: matchcount - 1\r\n                    });\r\n                    rule.token = rule.token[0];\r\n                } else {\r\n                    rule.tokenArray = rule.token;\r\n                    rule.token = null;\r\n                    rule.onMatch = this.$arrayTokens;\r\n                }\r\n            } else if (typeof rule.token == \"function\" && !rule.onMatch) {\r\n                if (matchcount > 1)\r\n                    rule.onMatch = this.$applyToken;\r\n                else\r\n                    rule.onMatch = rule.token;\r\n            }\r\n\r\n            if (matchcount > 1) {\r\n                if (/\\\\\\d/.test(rule.regex)) {\r\n                    // Replace any backreferences and offset appropriately.\r\n                    adjustedregex = rule.regex.replace(/\\\\([0-9]+)/g, function(match, digit) {\r\n                        return \"\\\\\" + (parseInt(digit, 10) + matchTotal + 1);\r\n                    });\r\n                } else {\r\n                    matchcount = 1;\r\n                    adjustedregex = this.removeCapturingGroups(rule.regex);\r\n                }\r\n                if (!rule.splitRegex && typeof rule.token != \"string\")\r\n                    splitterRurles.push(rule); // flag will be known only at the very end\r\n            }\r\n\r\n            mapping[matchTotal] = i;\r\n            matchTotal += matchcount;\r\n\r\n            ruleRegExps.push(adjustedregex);\r\n\r\n            // makes property access faster\r\n            if (!rule.onMatch)\r\n                rule.onMatch = null;\r\n        }\r\n        \r\n        if (!ruleRegExps.length) {\r\n            mapping[0] = 0;\r\n            ruleRegExps.push(\"$\");\r\n        }\r\n        \r\n        splitterRurles.forEach(function(rule) {\r\n            rule.splitRegex = this.createSplitterRegexp(rule.regex, flag);\r\n        }, this);\r\n\r\n        this.regExps[key] = new RegExp(\"(\" + ruleRegExps.join(\")|(\") + \")|($)\", flag);\r\n    }\r\n};\r\n\r\n(function() {\r\n    this.$setMaxTokenCount = function(m) {\r\n        MAX_TOKEN_COUNT = m | 0;\r\n    };\r\n    \r\n    this.$applyToken = function(str) {\r\n        var values = this.splitRegex.exec(str).slice(1);\r\n        var types = this.token.apply(this, values);\r\n\r\n        // required for compatibility with old modes\r\n        if (typeof types === \"string\")\r\n            return [{type: types, value: str}];\r\n\r\n        var tokens = [];\r\n        for (var i = 0, l = types.length; i < l; i++) {\r\n            if (values[i])\r\n                tokens[tokens.length] = {\r\n                    type: types[i],\r\n                    value: values[i]\r\n                };\r\n        }\r\n        return tokens;\r\n    };\r\n\r\n    this.$arrayTokens = function(str) {\r\n        if (!str)\r\n            return [];\r\n        var values = this.splitRegex.exec(str);\r\n        if (!values)\r\n            return \"text\";\r\n        var tokens = [];\r\n        var types = this.tokenArray;\r\n        for (var i = 0, l = types.length; i < l; i++) {\r\n            if (values[i + 1])\r\n                tokens[tokens.length] = {\r\n                    type: types[i],\r\n                    value: values[i + 1]\r\n                };\r\n        }\r\n        return tokens;\r\n    };\r\n\r\n    this.removeCapturingGroups = function(src) {\r\n        var r = src.replace(\r\n            /\\\\.|\\[(?:\\\\.|[^\\\\\\]])*|\\(\\?[:=!]|(\\()/g,\r\n            function(x, y) {return y ? \"(?:\" : x;}\r\n        );\r\n        return r;\r\n    };\r\n\r\n    this.createSplitterRegexp = function(src, flag) {\r\n        if (src.indexOf(\"(?=\") != -1) {\r\n            var stack = 0;\r\n            var inChClass = false;\r\n            var lastCapture = {};\r\n            src.replace(/(\\\\.)|(\\((?:\\?[=!])?)|(\\))|([\\[\\]])/g, function(\r\n                m, esc, parenOpen, parenClose, square, index\r\n            ) {\r\n                if (inChClass) {\r\n                    inChClass = square != \"]\";\r\n                } else if (square) {\r\n                    inChClass = true;\r\n                } else if (parenClose) {\r\n                    if (stack == lastCapture.stack) {\r\n                        lastCapture.end = index+1;\r\n                        lastCapture.stack = -1;\r\n                    }\r\n                    stack--;\r\n                } else if (parenOpen) {\r\n                    stack++;\r\n                    if (parenOpen.length != 1) {\r\n                        lastCapture.stack = stack;\r\n                        lastCapture.start = index;\r\n                    }\r\n                }\r\n                return m;\r\n            });\r\n\r\n            if (lastCapture.end != null && /^\\)*$/.test(src.substr(lastCapture.end)))\r\n                src = src.substring(0, lastCapture.start) + src.substr(lastCapture.end);\r\n        }\r\n        \r\n        // this is needed for regexps that can match in multiple ways\r\n        if (src.charAt(0) != \"^\") src = \"^\" + src;\r\n        if (src.charAt(src.length - 1) != \"$\") src += \"$\";\r\n        \r\n        return new RegExp(src, (flag||\"\").replace(\"g\", \"\"));\r\n    };\r\n\r\n    /**\r\n     * Returns an object containing two properties: `tokens`, which contains all the tokens; and `state`, the current state.\r\n     * @returns {Object}\r\n     **/\r\n    this.getLineTokens = function(line, startState) {\r\n        if (startState && typeof startState != \"string\") {\r\n            var stack = startState.slice(0);\r\n            startState = stack[0];\r\n            if (startState === \"#tmp\") {\r\n                stack.shift();\r\n                startState = stack.shift();\r\n            }\r\n        } else\r\n            var stack = [];\r\n\r\n        var currentState = startState || \"start\";\r\n        var state = this.states[currentState];\r\n        if (!state) {\r\n            currentState = \"start\";\r\n            state = this.states[currentState];\r\n        }\r\n        var mapping = this.matchMappings[currentState];\r\n        var re = this.regExps[currentState];\r\n        re.lastIndex = 0;\r\n\r\n        var match, tokens = [];\r\n        var lastIndex = 0;\r\n        var matchAttempts = 0;\r\n\r\n        var token = {type: null, value: \"\"};\r\n\r\n        while (match = re.exec(line)) {\r\n            var type = mapping.defaultToken;\r\n            var rule = null;\r\n            var value = match[0];\r\n            var index = re.lastIndex;\r\n\r\n            if (index - value.length > lastIndex) {\r\n                var skipped = line.substring(lastIndex, index - value.length);\r\n                if (token.type == type) {\r\n                    token.value += skipped;\r\n                } else {\r\n                    if (token.type)\r\n                        tokens.push(token);\r\n                    token = {type: type, value: skipped};\r\n                }\r\n            }\r\n\r\n            for (var i = 0; i < match.length-2; i++) {\r\n                if (match[i + 1] === undefined)\r\n                    continue;\r\n\r\n                rule = state[mapping[i]];\r\n\r\n                if (rule.onMatch)\r\n                    type = rule.onMatch(value, currentState, stack, line);\r\n                else\r\n                    type = rule.token;\r\n\r\n                if (rule.next) {\r\n                    if (typeof rule.next == \"string\") {\r\n                        currentState = rule.next;\r\n                    } else {\r\n                        currentState = rule.next(currentState, stack);\r\n                    }\r\n                    \r\n                    state = this.states[currentState];\r\n                    if (!state) {\r\n                        this.reportError(\"state doesn't exist\", currentState);\r\n                        currentState = \"start\";\r\n                        state = this.states[currentState];\r\n                    }\r\n                    mapping = this.matchMappings[currentState];\r\n                    lastIndex = index;\r\n                    re = this.regExps[currentState];\r\n                    re.lastIndex = index;\r\n                }\r\n                if (rule.consumeLineEnd)\r\n                    lastIndex = index;\r\n                break;\r\n            }\r\n\r\n            if (value) {\r\n                if (typeof type === \"string\") {\r\n                    if ((!rule || rule.merge !== false) && token.type === type) {\r\n                        token.value += value;\r\n                    } else {\r\n                        if (token.type)\r\n                            tokens.push(token);\r\n                        token = {type: type, value: value};\r\n                    }\r\n                } else if (type) {\r\n                    if (token.type)\r\n                        tokens.push(token);\r\n                    token = {type: null, value: \"\"};\r\n                    for (var i = 0; i < type.length; i++)\r\n                        tokens.push(type[i]);\r\n                }\r\n            }\r\n\r\n            if (lastIndex == line.length)\r\n                break;\r\n\r\n            lastIndex = index;\r\n\r\n            if (matchAttempts++ > MAX_TOKEN_COUNT) {\r\n                if (matchAttempts > 2 * line.length) {\r\n                    this.reportError(\"infinite loop with in ace tokenizer\", {\r\n                        startState: startState,\r\n                        line: line\r\n                    });\r\n                }\r\n                // chrome doens't show contents of text nodes with very long text\r\n                while (lastIndex < line.length) {\r\n                    if (token.type)\r\n                        tokens.push(token);\r\n                    token = {\r\n                        value: line.substring(lastIndex, lastIndex += 2000),\r\n                        type: \"overflow\"\r\n                    };\r\n                }\r\n                currentState = \"start\";\r\n                stack = [];\r\n                break;\r\n            }\r\n        }\r\n\r\n        if (token.type)\r\n            tokens.push(token);\r\n        \r\n        if (stack.length > 1) {\r\n            if (stack[0] !== currentState)\r\n                stack.unshift(\"#tmp\", currentState);\r\n        }\r\n        return {\r\n            tokens : tokens,\r\n            state : stack.length ? stack : currentState\r\n        };\r\n    };\r\n    \r\n    this.reportError = config.reportError;\r\n    \r\n}).call(Tokenizer.prototype);\r\n\r\nexports.Tokenizer = Tokenizer;\r\n});\r\n"]}